# -*- coding: utf-8 -*-
"""GIS ---> Implementation in Python

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pPGoEK-eEQ40B5Ey6oWd43G_GOXqYesZ
"""

## 1. Install dependencies
!pip install geopandas folium shapely rtree pyproj scikit-learn

import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
import folium
from sklearn.cluster import DBSCAN
from folium.plugins import HeatMap, MarkerCluster

shootings_df = pd.read_csv('/content/cleaned_shootings.csv')
hospitals_df = pd.read_csv('/content/hospitals_with_coordinates.csv')

shootings_df.columns

hospitals_df.columns

"""# 5. Create GeoDataFrames (WGS84)"""

shootings_gdf = gpd.GeoDataFrame(
    shootings_df,
    geometry=gpd.points_from_xy(shootings_df.lng, shootings_df.lat),
    crs="EPSG:4326"
)
hospitals_gdf = gpd.GeoDataFrame(
    hospitals_df,
    geometry=gpd.points_from_xy(hospitals_df.lng, hospitals_df.lat),
    crs="EPSG:4326"
)

shootings_proj = shootings_gdf.to_crs(epsg=3857)
hospitals_proj = hospitals_gdf.to_crs(epsg=3857)

shootings_proj

hospitals_proj

"""#Build spatial index for hospitals"""

hospital_sindex = hospitals_proj.sindex

hospital_sindex

"""#Nearest-hospital computation"""

def find_nearest(row, target_gdf, sindex):
    # Search within bounding box first
    bounds = row.geometry.bounds
    idx_candidates = list(sindex.intersection(bounds))
    candidates = target_gdf.iloc[idx_candidates] if idx_candidates else target_gdf
    # Use union_all() to merge geometries (replaces deprecated unary_union)
    merged = candidates.geometry.union_all()
    nearest_geom = nearest_points(row.geometry, merged)[1]
    nearest_row = candidates[candidates.geometry == nearest_geom].iloc[0]
    return nearest_row

nearest_list = [find_nearest(r, hospitals_proj, hospital_sindex) for _, r in shootings_proj.iterrows()]
nearest_hospitals = gpd.GeoDataFrame(nearest_list)

nearest_hospitals

nearest_list

"""#Distance calculation (meters)"""

print(hospitals_proj.columns)

id_col = 'hospital_id' if 'hospital_id' in hospitals_df.columns else hospitals_df.columns[0]
print(f"Using '{id_col}' as the hospital identifier column.")

# Assign nearest hospital ID
shootings_proj['nearest_hosp_id'] = nearest_hospitals[id_col].values

shootings_proj['nearest_hosp_id']

id_col = 'hospital_id' if 'hospital_id' in hospitals_df.columns else hospitals_df.columns[0]
print(f"Using '{id_col}' as the hospital identifier column.")

# Align nearest_hospitals index with shootings_proj for vectorized operations
nearest_hospitals.index = shootings_proj.index

# Assign nearest hospital ID
shootings_proj['nearest_hosp_id'] = nearest_hospitals[id_col]

# Calculate distances in meters between each shooting and its nearest hospital
shootings_proj['distance_m'] = shootings_proj.geometry.distance(nearest_hospitals.geometry)

## 6. Project to metric CRS (EPSG:3857)
shootings_proj = shootings_gdf.to_crs(epsg=3857)
hospitals_proj = hospitals_gdf.to_crs(epsg=3857)

hospital_sindex = hospitals_proj.sindex

def find_nearest(row, target_gdf, sindex):
    # Search within bounding box first
    bounds = row.geometry.bounds
    idx_candidates = list(sindex.intersection(bounds))
    candidates = target_gdf.iloc[idx_candidates] if idx_candidates else target_gdf
    # Use union_all() to merge geometries (replaces deprecated unary_union)
    merged = candidates.geometry.union_all()
    nearest_geom = nearest_points(row.geometry, merged)[1]
    nearest_row = candidates[candidates.geometry == nearest_geom].iloc[0]
    return nearest_row

# Find nearest hospitals for each shooting
nearest_list = [find_nearest(r, hospitals_proj, hospital_sindex) for _, r in shootings_proj.iterrows()]
# Construct GeoDataFrame and set the proper CRS
nearest_hospitals = gpd.GeoDataFrame(nearest_list, crs=hospitals_proj.crs)

# Identify the hospital ID column
id_col = 'hospital_id' if 'hospital_id' in hospitals_df.columns else hospitals_df.columns[0]
print(f"Using '{id_col}' as the hospital identifier column.")

# Align nearest_hospitals index with shootings_proj for vectorized operations
nearest_hospitals.index = shootings_proj.index

# Assign nearest hospital ID
shootings_proj['nearest_hosp_id'] = nearest_hospitals[id_col]

# Calculate distances in meters between each shooting and its nearest hospital
shootings_proj['distance_m'] = shootings_proj.geometry.distance(nearest_hospitals.geometry)

shootings_proj['distance_m']

"""#Back to WGS84 for visualization"""

results_gdf = shootings_proj.to_crs(epsg=4326)

"""#Folium map: shootings & hospitals"""

m = folium.Map(location=[results_gdf.lat.mean(), results_gdf.lng.mean()], zoom_start=11)
for _, row in results_gdf.iterrows():
    folium.CircleMarker([row.lat, row.lng], radius=4, color='red', fill=True).add_to(m)
for _, row in hospitals_df.iterrows():
    folium.Marker([row.lat, row.lng], icon=folium.Icon(color='blue', icon='hospital-symbol')).add_to(m)
# display
m

"""# Additional Spatial Analytics"""

# Prepare projected coordinates for clustering
eps_distance = 500  # in meters
coords = list(zip(shootings_proj.geometry.x, shootings_proj.geometry.y))
db = DBSCAN(eps=eps_distance, min_samples=5, metric='euclidean').fit(coords)
shootings_proj['cluster'] = db.labels_

clusters_gdf = shootings_proj.to_crs(epsg=4326)

cluster_map = folium.Map(location=[clusters_gdf.lat.mean(), clusters_gdf.lng.mean()], zoom_start=11)
marker_cluster = MarkerCluster().add_to(cluster_map)
for _, row in clusters_gdf.iterrows():
    color = 'gray' if row.cluster == -1 else None
    folium.CircleMarker([row.lat, row.lng], radius=5, color=color, fill=True, popup=f"Cluster {row.cluster}").add_to(marker_cluster)
# display
cluster_map

"""# Heatmap of shootings density"""

heat_data = [[pt.y, pt.x] for pt in shootings_gdf.geometry]
heatmap_map = folium.Map(location=[shootings_df.lat.mean(), shootings_df.lng.mean()], zoom_start=11)
HeatMap(heat_data, radius=15).add_to(heatmap_map)
# display
heatmap_map

"""# Kernel Density Estimation (KDE) Raster"""

import numpy as np
from scipy.stats import gaussian_kde
import matplotlib.pyplot as plt
from folium import raster_layers
from matplotlib import cm
# Extract coordinates in projected CRS
xy = np.vstack([shootings_proj.geometry.x, shootings_proj.geometry.y])
kde = gaussian_kde(xy)
# Create grid
xmin, ymin, xmax, ymax = shootings_proj.total_bounds
xx, yy = np.mgrid[xmin:xmax:500j, ymin:ymax:500j]
grid_coords = np.vstack([xx.ravel(), yy.ravel()])
# Evaluate KDE on grid
zz = kde(grid_coords).reshape(xx.shape)

plt.figure(figsize=(8,6))
plt.contourf(xx, yy, zz, levels=10)
plt.title('KDE Contour in Projected CRS')
plt.xlabel('X (meters)')
plt.ylabel('Y (meters)')
plt.show()

"""#Folium heatmap overlay using image
Normalize values for colormap
"""

norm = (zz - zz.min()) / (zz.max() - zz.min())

# Convert to RGBA image
colormap = cm.get_cmap('hot')
rgba_img = (colormap(norm) * 255).astype(np.uint8)

# Save RGBA as PNG
import imageio
imageio.imwrite('kde_overlay.png', rgba_img)

# Add overlay to Folium map
map_kde = folium.Map(location=[results_gdf.lat.mean(), results_gdf.lng.mean()], zoom_start=11)
raster = raster_layers.ImageOverlay(
    name='KDE Density',
    image='/content/kde_overlay.png',
    bounds=[[ymin, xmin], [ymax, xmax]],
    opacity=0.6
)
raster.add_to(map_kde)
folium.LayerControl().add_to(map_kde)
map_kde

from pyproj import Transformer
# Reproject grid bounds from EPSG:3857 to WGS84
transformer = Transformer.from_crs('EPSG:3857', 'EPSG:4326', always_xy=True)
west, south = transformer.transform(xmin, ymin)
east, north = transformer.transform(xmax, ymax)
geo_bounds = [[south, west], [north, east]]  # [[min_lat, min_lon], [max_lat, max_lon]]

# Create Folium map and add the KDE overlay
map_kde = folium.Map(location=[results_gdf.lat.mean(), results_gdf.lng.mean()], zoom_start=11)
raster = raster_layers.ImageOverlay(
    name='KDE Density',
    image='/content/kde_overlay.png',
    bounds=geo_bounds,
    opacity=0.6
)
raster.add_to(map_kde)
folium.LayerControl().add_to(map_kde)
map_kde

"""#Hospital Incident Summary & Visualization"""

id_col = 'nearest_hosp_id'
summary = shootings_proj.groupby(id_col).agg(
    incident_count=('nearest_hosp_id', 'size'),
    mean_distance_m=('distance_m', 'mean')
).reset_index()

# Merge with hospital coordinates
df_hosp = hospitals_df.copy()
if id_col not in df_hosp.columns:
    df_hosp.rename(columns={df_hosp.columns[0]: id_col}, inplace=True)
merged = summary.merge(df_hosp, on=id_col)

merged

"""# Top 10 hospitals by incident count"""

top10 = merged.nlargest(10, 'incident_count')
import matplotlib.pyplot as plt
plt.figure(figsize=(10,6))
plt.bar(top10[id_col].astype(str), top10['incident_count'])
plt.xticks(rotation=45)
plt.title('Top 10 Hospitals by Number of Nearby Shootings')
plt.xlabel('Hospital ID')
plt.ylabel('Number of Shootings')
plt.tight_layout()
plt.show()

# Interactive map: circle size âˆ incident count
map_summary = folium.Map(location=[results_gdf.lat.mean(), results_gdf.lng.mean()], zoom_start=11)
for _, row in merged.iterrows():
    folium.CircleMarker(
        [row.lat, row.lng],
        radius=max(5, row.incident_count**0.5),
        color='purple', fill=True,
        popup=f"Hospital {row[id_col]}: {row.incident_count} shootings, avg dist {row.mean_distance_m:.1f}m"
    ).add_to(map_summary)
map_summary

"""#Buffer Zone Analysis"""

# Create buffers around hospitals at multiple radii (meters)
radii = [500, 1000, 2000]
buffer_summary = []
for r in radii:
    buf = hospitals_proj.copy()
    buf['geometry'] = buf.geometry.buffer(r)
    joined = gpd.sjoin(shootings_proj, buf[['geometry']], how='inner', predicate='within')
    counts = joined.groupby('nearest_hosp_id').size().reset_index(name='shooting_count')
    counts['radius_m'] = r
    buffer_summary.append(counts)
buffer_df = pd.concat(buffer_summary, ignore_index=True)
print(buffer_df.head())

"""# Nearest-Neighbor Distance Distribution"""

import matplotlib.pyplot as plt
# Histogram of distances to nearest hospital
dists = shootings_proj['distance_m']
plt.figure(figsize=(8,5))
plt.hist(dists, bins=30)
plt.title('Distance to Nearest Hospital')
plt.xlabel('Distance (m)')
plt.ylabel('Frequency')
plt.show()

"""#Hotspot Analysis with Getis-Ord Gi"""

!pip install libpysal
!pip install esda

import libpysal
from esda.getisord import G_Local
from shapely.geometry import Polygon
# Create fishnet grid (1km cells)
cell_size = 1000
xmin, ymin, xmax, ymax = shootings_proj.total_bounds
cols = int((xmax - xmin) / cell_size) + 1
rows = int((ymax - ymin) / cell_size) + 1
polys = []
for i in range(cols):
    for j in range(rows):
        x0 = xmin + i * cell_size
        y0 = ymin + j * cell_size
        polys.append(Polygon([(x0, y0), (x0 + cell_size, y0), (x0 + cell_size, y0 + cell_size), (x0, y0 + cell_size)]))
grid = gpd.GeoDataFrame({'geometry': polys}, crs=shootings_proj.crs)

# Count incidents per cell
grid['count'] = grid.geometry.apply(lambda poly: shootings_proj.within(poly).sum())

# Cast to float to avoid dtype mismatches
grid['count'] = grid['count'].astype(float)

# Build spatial weights (Queen contiguity)
w = libpysal.weights.Queen.from_dataframe(grid)

# Compute local Getis-Ord Gi* (use default permutations)
g = G_Local(grid['count'], w)

# Attach results
grid['GiZ'] = g.Zs
grid['GiP'] = g.p_sim

# Identify hotspots (high Z-score and significant p)
hotspots = grid[(grid['GiZ'] > 2) & (grid['GiP'] < 0.05)]

hotspots

# Visualize hotspots

map_hot = folium.Map(location=[results_gdf.lat.mean(), results_gdf.lng.mean()], zoom_start=11)
folium.GeoJson(
    hotspots.to_crs(epsg=4326),
    style_function=lambda feature: {
        'fillColor': 'red',
        'color': 'red',
        'weight': 1,
        'fillOpacity': 0.6
    }
).add_to(map_hot)
map_hot

"""#Spatio-Temporal Animation of Shootings. Spatio-Temporal Animation of Shootings Spatio-Temporal Animation of Shootings"""

from folium.plugins import TimestampedGeoJson
import pandas as pd
# Detect and prepare date column
date_cols = [c for c in shootings_df.columns if 'date' in c.lower()]
if not date_cols:
    raise ValueError("No date-like column found for temporal animation. Please ensure your DataFrame has a date/time column.")
date_col = date_cols[0]
shootings_df[date_col] = pd.to_datetime(shootings_df[date_col], errors='coerce')
# Drop rows without a valid datetime
valid = shootings_df.dropna(subset=[date_col])
# Rebuild shooting GeoDataFrame with dates
shootings_gdf = gpd.GeoDataFrame(
    valid,
    geometry=gpd.points_from_xy(valid.lng, valid.lat),
    crs="EPSG:4326"
)

# Prepare features for TimestampedGeoJson
features = []
for _, row in shootings_gdf.iterrows():
    features.append({
        'type': 'Feature',
        'geometry': {
            'type': 'Point',
            'coordinates': [row.geometry.x, row.geometry.y]
        },
        'properties': {
            'time': row[date_col].isoformat(),
            'style': {'color': 'red', 'radius': 4}
        }
    })

# Create map with time slider
m_time = folium.Map(location=[results_gdf.lat.mean(), results_gdf.lng.mean()], zoom_start=11)
TimestampedGeoJson(
    {'type':'FeatureCollection', 'features': features},
    period='P1D',
    add_last_point=True,
    auto_play=False,
    loop=False,
    max_speed=1,
    loop_button=True
).add_to(m_time)

# Display map
m_time

"""#Standard Deviational Ellipse of Shootings"""

import numpy as np
from shapely.geometry import Point
from shapely.affinity import scale, rotate, translate

# Compute centroid in projected CRS
x_mean = shootings_proj.geometry.x.mean()
y_mean = shootings_proj.geometry.y.mean()

# Covariance matrix of coordinates
data = np.vstack([shootings_proj.geometry.x, shootings_proj.geometry.y])
cov = np.cov(data)

# Eigen decomposition
eigvals, eigvecs = np.linalg.eig(cov)
# Compute axes lengths (2 std dev)
axes_lengths = 2 * np.sqrt(eigvals)
# Create unit circle and transform to ellipse
euc = Point(0,0).buffer(1,256)
ellipse = scale(euc, axes_lengths[0], axes_lengths[1])
# Compute rotation angle (in degrees)
angle = np.degrees(np.arctan2(eigvecs[0,1], eigvecs[0,0]))
ellipse = rotate(ellipse, angle, origin=(0,0))
ellipse = translate(ellipse, x_mean, y_mean)
# Convert to GeoDataFrame and to WGS84
ellipse_gdf = gpd.GeoDataFrame({'geometry':[ellipse]}, crs=shootings_proj.crs).to_crs(epsg=4326)

# Map ellipse
map_sde = folium.Map(location=[results_gdf.lat.mean(), results_gdf.lng.mean()], zoom_start=11)
folium.GeoJson(ellipse_gdf).add_to(map_sde)
map_sde

"""#Average Nearest Neighbor Index"""

from sklearn.neighbors import NearestNeighbors
# Coordinates in projected CRS
coords = np.vstack([shootings_proj.geometry.x, shootings_proj.geometry.y]).T
nbrs = NearestNeighbors(n_neighbors=2).fit(coords)
dists, idxs = nbrs.kneighbors(coords)
# Exclude self-distance (zero), take first neighbor distances
d1 = dists[:,1]
mean_nnd = d1.mean()
# Compute expected NND for CSR: 0.5 / sqrt(lambda), lambda = n/area
area = shootings_proj.unary_union.convex_hull.area
n = len(d1)
expected_nnd = 0.5 / np.sqrt(n/area)
R = mean_nnd / expected_nnd
print(f"Mean NND: {mean_nnd:.2f} m, Expected: {expected_nnd:.2f} m, Index R: {R:.2f}")

"""#K-Means Clustering of Hospitals"""

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
# Prepare hospital summary from section 19 (merged)
features = merged[['incident_count', 'mean_distance_m']].copy()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(features)

# Fit KMeans
kmeans = KMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X_scaled)
merged['cluster_hosp'] = labels

# Scatter plot of incident_count vs mean_distance_m colored by cluster
import matplotlib.pyplot as plt
plt.figure(figsize=(8,6))
for cl in merged['cluster_hosp'].unique():
    sub = merged[merged['cluster_hosp']==cl]
    plt.scatter(sub['incident_count'], sub['mean_distance_m'], label=f"Cluster {cl}")
plt.xlabel('Incident Count')
plt.ylabel('Mean Distance (m)')
plt.title('Hospital Clusters by Shooting Incidents')
plt.legend()
plt.show()

# Folium map of hospital clusters
cluster_map = folium.Map(location=[results_gdf.lat.mean(), results_gdf.lng.mean()], zoom_start=11)
colors = ['blue','green','orange']
for _, row in merged.iterrows():
    folium.CircleMarker([
        row.lat, row.lng
    ], radius=6, color=colors[row['cluster_hosp']], fill=True,
       popup=f"Hosp {row[id_col]}: Cluster {row['cluster_hosp']}").add_to(cluster_map)
cluster_map

"""#Hotspot Classification with Random Forest"""

from sklearn.ensemble import RandomForestClassifier
# Prepare grid from hotspot analysis
grid = grid.copy()  # from section 22
# Define target: hotspot flag
grid['hotspot_flag'] = ((grid['GiZ'] > 2) & (grid['GiP'] < 0.05)).astype(int)
# Extract centroids for features
grid['centroid_x'] = grid.geometry.centroid.x
grid['centroid_y'] = grid.geometry.centroid.y
# Feature matrix and target
df_ml = grid.dropna(subset=['hotspot_flag'])
X = df_ml[['centroid_x', 'centroid_y']]
y = df_ml['hotspot_flag']

# Train/test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)
# Train Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Evaluate
from sklearn.metrics import classification_report
y_pred = rf.predict(X_test)
print(classification_report(y_test, y_pred))

# Predict probabilities on full grid
grid['hotspot_prob'] = rf.predict_proba(grid[['centroid_x','centroid_y']])[:,1]
# Prepare grid with ID column for mapping
map_grid = grid.reset_index().rename(columns={'index': 'grid_id'})
# Folium choropleth of hotspot probability
choromap = folium.Map(location=[results_gdf.lat.mean(), results_gdf.lng.mean()], zoom_start=11)
folium.Choropleth(
    geo_data=map_grid.to_crs(epsg=4326).set_index('grid_id'),
    data=map_grid,
    columns=['grid_id', 'hotspot_prob'],
    key_on='feature.id',
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name='Hotspot Probability'
).add_to(choromap)
choromap

